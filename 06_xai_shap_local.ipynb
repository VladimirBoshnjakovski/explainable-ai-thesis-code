{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VladimirBoshnjakovski/explainable-ai-thesis-code/blob/main/06_xai_shap_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ IMPORTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, regularizers, optimizers\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "b2xGNPp3AxYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the dataset file from your computer\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "df = pd.read_csv(next(iter(uploaded)))\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ PREPROCESS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "# Assume df already loaded\n",
        "df = df.drop(columns=['source']) \\\n",
        "       .rename(columns={'Presence of Heart Disease (1=Yes)': 'target'})"
      ],
      "metadata": {
        "id": "6TfuArwXCPL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(columns=['target']).values\n",
        "y = df['target'].values\n",
        "\n",
        "# stratified train/test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# standardize\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "a_VwtZwCCW61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ MODEL BUILDER ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, regularizers, optimizers\n",
        "\n",
        "def build_model(input_dim):\n",
        "    l2 = regularizers.l2(1e-4)\n",
        "    model = models.Sequential([\n",
        "        layers.Input(shape=(input_dim,)),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=l2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(32, activation='relu', kernel_regularizer=l2),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(16, activation='relu', kernel_regularizer=l2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    # lower learning rate, track AUC\n",
        "    opt = optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(\n",
        "        optimizer=opt,\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "model = build_model(X_train.shape[1])\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ CALLBACKS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "es = callbacks.EarlyStopping(\n",
        "    monitor='val_auc',      # stop when AUC stops improving\n",
        "    mode='max',             # we want to MAXIMIZE AUC\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "rlr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=5,\n",
        "    min_lr=1e-5,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ TRAIN ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    callbacks=[es, rlr],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ EVALUATE ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "loss, acc, auc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test loss: {loss:.4f}   |   Test accuracy: {acc:.4f}   |   Test AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "id": "62rCwassCbEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ SHAP LOCAL INTERPRETATIONS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
        "import shap\n",
        "import time\n",
        "\n",
        "# Initialize the SHAP explainer\n",
        "explainer = shap.KernelExplainer(model.predict, X_train)\n",
        "\n",
        "# Instance to explain (instance 40 from the test set)\n",
        "instance_idx = 40\n",
        "x_instance = X_test[instance_idx].reshape(1, -1)"
      ],
      "metadata": {
        "id": "P6C_Ejw3Dci_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming explainer is already initialized and x_instance is defined\n",
        "shap_values_list = []\n",
        "time_taken_list = []\n",
        "\n",
        "# Run SHAP local interpretation 3 times and calculate the time taken for each\n",
        "for i in range(5):\n",
        "    start_time = time.time()\n",
        "    shap_values = explainer.shap_values(x_instance)\n",
        "    end_time = time.time()\n",
        "\n",
        "    shap_values_list.append(shap_values)\n",
        "    time_taken_list.append(end_time - start_time)\n",
        "\n"
      ],
      "metadata": {
        "id": "4IqdiulyZWFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Example for a specific instance (let's assume instance index 40 as an example)\n",
        "instance_idx = 40\n",
        "shap_values = shap_values_list[0]  # Treating this as an example (first run)\n",
        "\n",
        "# Flatten the SHAP values from the run\n",
        "shap_values_flat = shap_values[0].flatten()\n",
        "\n",
        "# Get the feature names from your dataset\n",
        "feature_names = df.drop(columns=['target']).columns.tolist()\n",
        "\n",
        "# Create a DataFrame to map SHAP values to feature names\n",
        "shap_values_df = pd.DataFrame(shap_values_flat, columns=[\"SHAP Value\"])\n",
        "shap_values_df[\"Feature\"] = feature_names  # Link feature names to SHAP values\n",
        "\n",
        "# Compute the absolute value for sorting\n",
        "shap_values_df[\"abs_SHAP Value\"] = shap_values_df[\"SHAP Value\"].abs()\n",
        "\n",
        "# Sort the DataFrame by absolute SHAP Value in descending order\n",
        "shap_values_df = shap_values_df.sort_values(by=\"abs_SHAP Value\", ascending=False)\n",
        "\n",
        "# Select top 8 features with the highest absolute SHAP values\n",
        "top_features = shap_values_df.head(8)\n",
        "\n",
        "# Set a sketch-like style with Seaborn\n",
        "sns.set(style=\"white\", palette=\"muted\", font_scale=1.2)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot using Seaborn's barplot with coloring based on the \"Set2\" color palette\n",
        "sns.barplot(x=\"SHAP Value\", y=\"Feature\", data=top_features, color=sns.color_palette(\"Set2\", n_colors=1)[0], edgecolor='black', linewidth=2)\n",
        "\n",
        "# Add gridlines for a \"net\" effect\n",
        "plt.grid(True, axis='x', linestyle='--', linewidth=0.7, color='gray', alpha=0.5)\n",
        "\n",
        "# Set labels and title with a bit more padding and font size\n",
        "plt.xlabel('SHAP Value', fontsize=12, labelpad=10)\n",
        "plt.ylabel('Feature', fontsize=12, labelpad=10)\n",
        "\n",
        "# Title in two lines with bold font\n",
        "plt.title(f'Top 8 Most Influential Features\\nBased on Absolute SHAP Values for Instance {instance_idx}', fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "# Adjust the layout to avoid clipping the labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "fzRbutdAhnBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "shap.initjs()\n",
        "\n",
        "# Instance to explain\n",
        "instance_index = 40\n",
        "x_instance_raw = X_test[instance_index].reshape(1, -1)\n",
        "\n",
        "# Recompute SHAP values\n",
        "shap_values = explainer.shap_values(x_instance_raw)\n",
        "\n",
        "# Flatten\n",
        "shap_value_instance = shap_values[0].flatten()\n",
        "x_instance = x_instance_raw.flatten()\n",
        "feature_names = df.drop(columns='target').columns.tolist()\n",
        "\n",
        "# Top 8\n",
        "top8_indices = np.argsort(np.abs(shap_value_instance))[::-1][:8]\n",
        "shap_top8 = shap_value_instance[top8_indices]\n",
        "x_top8 = x_instance[top8_indices]\n",
        "feature_names_top8 = [feature_names[i] for i in top8_indices]\n",
        "x_top8_2D = x_top8.reshape(1, -1)\n",
        "\n"
      ],
      "metadata": {
        "id": "McDrtdJF-OAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten\n",
        "shap_value_instance = shap_values[0].flatten()\n",
        "x_instance = x_instance_raw.flatten()\n",
        "feature_names = df.drop(columns='target').columns.tolist()\n",
        "\n",
        "# Top 8\n",
        "top8_indices = np.argsort(np.abs(shap_value_instance))[::-1][:8]\n",
        "shap_top8 = shap_value_instance[top8_indices]\n",
        "x_top8 = x_instance[top8_indices]\n",
        "feature_names_top8 = [feature_names[i] for i in top8_indices]\n",
        "x_top8_2D = x_top8.reshape(1, -1)\n",
        "\n",
        "# Display in notebook\n",
        "shap_plot = shap.force_plot(\n",
        "    base_value     = explainer.expected_value[0],\n",
        "    shap_values    = shap_top8,\n",
        "    features       = x_top8_2D,\n",
        "    feature_names  = feature_names_top8\n",
        ")\n",
        "\n",
        "# Show + Save to HTML\n",
        "shap_plot\n",
        "shap.save_html(\"shap_forceplot_instance_40.html\", shap_plot)"
      ],
      "metadata": {
        "id": "QNjRBfImCi1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "force_plot = shap.force_plot(\n",
        "    base_value     = explainer.expected_value[0],\n",
        "    shap_values    = shap_top8,\n",
        "    features       = x_top8_2D,\n",
        "    feature_names  = feature_names_top8\n",
        ")\n"
      ],
      "metadata": {
        "id": "8S8lkRRsBMQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and trigger download\n",
        "shap.save_html(\"shap_force_plot_instance40.html\", force_plot)\n",
        "files.download(\"shap_force_plot_instance40.html\")"
      ],
      "metadata": {
        "id": "zz34qGCWCyrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# Activate JS-based plotting\n",
        "shap.initjs()\n",
        "\n",
        "# Step 1: Choose instance to explain\n",
        "instance_index = 30\n",
        "x_instance_raw = X_test[instance_index].reshape(1, -1)      # shape: (1, n_features)\n",
        "\n",
        "# Step 2: Recompute SHAP values for this instance\n",
        "shap_values = explainer.shap_values(x_instance_raw)         # shape: (1, n_features, 1)\n",
        "\n",
        "# Step 3: Flatten SHAP values and input features\n",
        "shap_value_instance = shap_values[0].flatten()              # shape: (n_features,)\n",
        "x_instance = x_instance_raw.flatten()                       # shape: (n_features,)\n",
        "feature_names = df.drop(columns='target').columns.tolist()  # list of feature names\n",
        "\n",
        "# Step 4: Get top 8 features by absolute SHAP value\n",
        "top8_indices = np.argsort(np.abs(shap_value_instance))[::-1][:8]\n",
        "shap_top8 = shap_value_instance[top8_indices]\n",
        "x_top8 = x_instance[top8_indices]\n",
        "feature_names_top8 = [feature_names[i] for i in top8_indices]\n",
        "\n",
        "# Step 5: Reshape input features for SHAP\n",
        "x_top8_2D = x_top8.reshape(1, -1)\n",
        "\n",
        "# Step 6: Plot SHAP force plot\n",
        "print(f\"üîç SHAP Force Plot ‚Äì Instance #{instance_index}\")\n",
        "shap.force_plot(\n",
        "    base_value     = explainer.expected_value[0],\n",
        "    shap_values    = shap_top8,\n",
        "    features       = x_top8_2D,\n",
        "    feature_names  = feature_names_top8\n",
        ")\n"
      ],
      "metadata": {
        "id": "m8evC_hBAoRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "\n",
        "# Activate JS-based plotting\n",
        "shap.initjs()\n",
        "\n",
        "# Step 1: Choose instance to explain\n",
        "instance_index = 50\n",
        "x_instance_raw = X_test[instance_index].reshape(1, -1)      # shape: (1, n_features)\n",
        "\n",
        "# Step 2: Recompute SHAP values for this instance\n",
        "shap_values = explainer.shap_values(x_instance_raw)         # shape: (1, n_features, 1)\n",
        "\n",
        "# Step 3: Flatten SHAP values and input features\n",
        "shap_value_instance = shap_values[0].flatten()              # shape: (n_features,)\n",
        "x_instance = x_instance_raw.flatten()                       # shape: (n_features,)\n",
        "feature_names = df.drop(columns='target').columns.tolist()  # list of feature names\n",
        "\n",
        "# Step 4: Get top 8 features by absolute SHAP value\n",
        "top8_indices = np.argsort(np.abs(shap_value_instance))[::-1][:8]\n",
        "shap_top8 = shap_value_instance[top8_indices]\n",
        "x_top8 = x_instance[top8_indices]\n",
        "feature_names_top8 = [feature_names[i] for i in top8_indices]\n",
        "\n",
        "# Step 5: Reshape input features for SHAP\n",
        "x_top8_2D = x_top8.reshape(1, -1)\n",
        "\n",
        "# Step 6: Plot SHAP force plot\n",
        "print(f\"üîç SHAP Force Plot ‚Äì Instance #{instance_index}\")\n",
        "shap.force_plot(\n",
        "    base_value     = explainer.expected_value[0],\n",
        "    shap_values    = shap_top8,\n",
        "    features       = x_top8_2D,\n",
        "    feature_names  = feature_names_top8\n",
        ")\n"
      ],
      "metadata": {
        "id": "pGUkG9VBAqnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "shap.initjs()\n",
        "\n",
        "# Step 1: Flatten SHAP values (shape: (28,))\n",
        "shap_value_instance = shap_values[0].flatten()\n",
        "\n",
        "# Step 2: Get feature names and feature values\n",
        "feature_names = df.drop(columns='target').columns.tolist()\n",
        "x_instance = X_test[0].reshape(-1)  # 1D array of 28 features\n",
        "\n",
        "# Step 3: Get top 8 feature indices by absolute SHAP value\n",
        "top8_indices = np.argsort(np.abs(shap_value_instance))[::-1][:8]\n",
        "\n",
        "# Step 4: Subset SHAP values, feature values, and names\n",
        "shap_top8 = shap_value_instance[top8_indices]\n",
        "x_top8 = x_instance[top8_indices]\n",
        "feature_names_top8 = [feature_names[i] for i in top8_indices]\n",
        "\n",
        "# Step 5: Reshape feature vector for SHAP input (shape: (1, 8))\n",
        "x_top8_2D = x_top8.reshape(1, -1)\n",
        "\n",
        "# Step 6: Plot\n",
        "shap.force_plot(\n",
        "    base_value     = explainer.expected_value[0],\n",
        "    shap_values    = shap_top8,\n",
        "    features       = x_top8_2D,\n",
        "    feature_names  = feature_names_top8\n",
        ")\n"
      ],
      "metadata": {
        "id": "AQtpJtRu_n25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Process each SHAP value for each run\n",
        "shap_values_df_list = []\n",
        "\n",
        "for shap_values in shap_values_list:\n",
        "    shap_values_flat = shap_values[0].flatten()  # Flatten SHAP values\n",
        "\n",
        "    # Create DataFrame\n",
        "    shap_values_df = pd.DataFrame(shap_values_flat, columns=[\"SHAP Value\"])\n",
        "    shap_values_df[\"Feature\"] = feature_names  # Link feature names to SHAP values\n",
        "    shap_values_df[\"abs_SHAP Value\"] = shap_values_df[\"SHAP Value\"].abs()  # Absolute value for sorting\n",
        "\n",
        "    shap_values_df_list.append(shap_values_df)\n",
        "\n",
        "# Combine the SHAP values from all runs into one DataFrame\n",
        "combined_shap_values = pd.concat([df.set_index(\"Feature\")[\"SHAP Value\"] for df in shap_values_df_list], axis=1)\n",
        "combined_shap_values.columns = [f\"Run {i+1}\" for i in range(len(shap_values_df_list))]\n",
        "\n",
        "# Sort the values based on the absolute value of SHAP values and select the top 5 features\n",
        "combined_shap_values = combined_shap_values.reindex(combined_shap_values.abs().max(axis=1).sort_values(ascending=False).index).head(5)\n",
        "\n",
        "# Reshape the data to be suitable for Seaborn\n",
        "combined_shap_values = combined_shap_values.reset_index()\n",
        "combined_shap_values = pd.melt(combined_shap_values, id_vars=\"Feature\", var_name=\"Run\", value_name=\"SHAP Value\")\n",
        "\n",
        "# Set a sketch-like style\n",
        "sns.set(style=\"white\", palette=\"muted\", font_scale=1.2)\n",
        "\n",
        "# Create the plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot using Seaborn's barplot with a \"sketch\" theme\n",
        "sns.barplot(x=\"SHAP Value\", y=\"Feature\", hue=\"Run\", data=combined_shap_values, dodge=True,\n",
        "            edgecolor='black', linewidth=2, capsize=5, errwidth=2)\n",
        "\n",
        "# Add a vertical line at zero\n",
        "plt.axvline(x=0, color='black', linestyle='--', linewidth=1.5)\n",
        "\n",
        "# Add gridlines for the \"net\" effect (background grid)\n",
        "plt.grid(True, linestyle='--', linewidth=0.7, color='gray', alpha=0.5)\n",
        "\n",
        "# Set labels and title with a bit more padding and font size\n",
        "plt.xlabel('SHAP Value', fontsize=12, labelpad=10)\n",
        "plt.ylabel('Feature', fontsize=12, labelpad=10)\n",
        "plt.title('SHAP Values for Top 5 Features Across Runs', fontsize=14, pad=20)\n",
        "\n",
        "# Adjust the layout to avoid clipping the labels\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-z7r6RWbg8GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for feature in combined_shap_values[\"Feature\"].unique():\n",
        "    subset = combined_shap_values[combined_shap_values[\"Feature\"] == feature]\n",
        "    plt.plot(subset[\"Run\"], subset[\"SHAP Value\"], marker='o', label=feature)\n",
        "\n",
        "plt.axhline(0, color='black', linestyle='--')\n",
        "plt.xlabel(\"Run\")\n",
        "plt.ylabel(\"SHAP Value\")\n",
        "plt.title(\"SHAP Values Across Runs for Top 5 Features\")\n",
        "plt.legend(title=\"Feature\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.tight_layout()\n",
        "plt.grid(True, linestyle='--', linewidth=0.5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mSz3G8Kl2Qc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot = combined_shap_values.pivot(index=\"Feature\", columns=\"Run\", values=\"SHAP Value\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(pivot, annot=True, cmap=\"coolwarm\", center=0, linewidths=0.5, linecolor='gray')\n",
        "plt.title(\"SHAP Value Heatmap for Top 5 Features Across Runs\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UywEb0Yt2W1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.stripplot(data=combined_shap_values, x=\"SHAP Value\", y=\"Feature\", hue=\"Run\", jitter=True, dodge=True, size=8)\n",
        "plt.axvline(0, color='black', linestyle='--')\n",
        "plt.title(\"SHAP Values Distribution (Dot Plot)\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WCdu2pRn2nev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "std_dev_df = combined_shap_values.groupby(\"Feature\")[\"SHAP Value\"].std().sort_values(ascending=False).reset_index()\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=\"SHAP Value\", y=\"Feature\", data=std_dev_df, palette=\"OrRd\")\n",
        "plt.xlabel(\"Standard Deviation of SHAP Value\")\n",
        "plt.title(\"Feature-wise SHAP Variability Across Runs\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_hmE4iBa2rWA"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO960BTwJAuopowDA9vaezp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}